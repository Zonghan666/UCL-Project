{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment you will build a language model for the [OHHLA corpus](http://ohhla.com/) we are using in the book. You will train the model on the available training set, and can tune it on the development set. After submission we will run your notebook on a different test set. Your mark will depend on \n",
    "\n",
    "* whether your language model is **properly normalized**,\n",
    "* its **perplexity** on the unseen test set,\n",
    "* your **description** of your approach. \n",
    "\n",
    "To develop your model you have access to:\n",
    "\n",
    "* The training and development data in `data/ohhla`.\n",
    "* The code of the lecture, stored in a python module [here](/edit/statnlpbook/lm.py).\n",
    "* Libraries on the [docker image](https://github.com/uclmr/stat-nlp-book/blob/python/Dockerfile) which contains everything in [this image](https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook), including scikit-learn and tensorflow. \n",
    "\n",
    "As we have to run the notebooks of all students, and because writing efficient code is important, **your notebook should run in 5 minutes at most**, on your machine. Further comments:\n",
    "\n",
    "* We have tested a possible solution on the Azure VMs and it ran in seconds, so it is possible to train a reasonable LM on the data in reasonable time. \n",
    "\n",
    "* Try to run your parameter optimisation offline, such that in your answer notebook the best parameters are already set and don't need to be searched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "It is important that this file is placed in the **correct directory**. It will not run otherwise. The correct directory is\n",
    "\n",
    "    DIRECTORY_OF_YOUR_BOOK/assignments/2017/assignment1/problem/\n",
    "    \n",
    "where `DIRECTORY_OF_YOUR_BOOK` is a placeholder for the directory you downloaded the book to. After you placed it there, **rename the file** to your UCL ID (of the form `ucxxxxx`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Instructions\n",
    "This notebook will be used by you to provide your solution, and by us to both assess your solution and enter your marks. It contains three types of sections:\n",
    "\n",
    "1. **Setup** Sections: these sections set up code and resources for assessment. **Do not edit these**. \n",
    "2. **Assessment** Sections: these sections are used for both evaluating the output of your code, and for markers to enter their marks. **Do not edit these**. \n",
    "3. **Task** Sections: these sections require your solutions. They may contain stub code, and you are expected to edit this code. For free text answers simply edit the markdown field.  \n",
    "\n",
    "Note that you are free to **create additional notebook cells** within a task section. \n",
    "\n",
    "Please **do not share** this assignment publicly, by uploading it online, emailing it to friends etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To submit your solution:\n",
    "\n",
    "* Make sure that your solution is fully contained in this notebook. \n",
    "* **Rename this notebook to your UCL ID** (of the form \"ucxxxxx\"), if you have not already done so.\n",
    "* Download the notebook in Jupyter via *File -> Download as -> Notebook (.ipynb)*.\n",
    "* Upload the notebook to the Moodle submission site.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 1</font>: Load Libraries\n",
    "This cell loads libraries important for evaluation and assessment of your model. **Do not change it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! SETUP 1\n",
    "import sys, os\n",
    "_snlp_book_dir = \"../../../../\"\n",
    "sys.path.append(_snlp_book_dir) \n",
    "import statnlpbook.lm as lm\n",
    "import statnlpbook.ohhla as ohhla\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 2</font>: Load Training Data\n",
    "\n",
    "This cell loads the training data. We use this data for assessment to define the reference vocabulary: the union of the words of the training and set set. You can use the dataset to train your model, but you are also free to load the data in a different way, or focus on subsets etc. However, when you do this, still **do not edit this setup section**. Instead refer to the variables in your own code, and slice and dice them as you see fit.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not load ../../../..//data/ohhla/train/www.ohhla.com/anonymous/nas/distant/tribal.nas.txt.html\n"
     ]
    }
   ],
   "source": [
    "#! SETUP 2\n",
    "_snlp_train_dir = _snlp_book_dir + \"/data/ohhla/train\"\n",
    "_snlp_dev_dir = _snlp_book_dir + \"/data/ohhla/dev\"\n",
    "_snlp_train_song_words = ohhla.words(ohhla.load_all_songs(_snlp_train_dir))\n",
    "_snlp_dev_song_words = ohhla.words(ohhla.load_all_songs(_snlp_dev_dir))\n",
    "assert(len(_snlp_train_song_words)==1041496)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to file encoding issues this code produces one error `Could not load ...`. **Ignore this error**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 1</font>: Develop and Train the Model\n",
    "\n",
    "This is the core part of the assignment. You are to code up, train and tune a language model. Your language model needs to be subclass of the `lm.LanguageModel` class. You can use some of the existing language models developed in the lecture, or develop your own extensions. \n",
    "\n",
    "Concretely, you need to return a better language model in the `create_lm` function. This function receives a target vocabulary `vocab`, and it needs to return a language model defined over this vocabulary. \n",
    "\n",
    "The target vocab will be the union of the training and test set (hidden to you at development time). This vocab will contain words not in the training set. One way to address this issue is to use the `lm.OOVAwareLM` class discussed in the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## You should improve this cell\n",
    "def create_lm(vocab):\n",
    "    \"\"\"\n",
    "    Return an instance of `lm.LanguageModel` defined over the given vocabulary.\n",
    "    Args:\n",
    "        vocab: the vocabulary the LM should be defined over. It is the union of the training and test words.\n",
    "    Returns:\n",
    "        a language model, instance of `lm.LanguageModel`.\n",
    "    \"\"\"\n",
    "  \n",
    "    class KN_NGramLM(lm.CountLM):\n",
    "        \n",
    "        def __init__(self, train, order):\n",
    "            super().__init__(set(train), order)\n",
    "            self._counts = lm.collections.defaultdict(float)\n",
    "            self._norm = lm.collections.defaultdict(float)\n",
    "            self._NgramCounts = 0.0\n",
    "            self._wordPairCounts = lm.collections.defaultdict(float)\n",
    "            self._historyPairCounts = lm.collections.defaultdict(float)\n",
    "            for i in range(self.order, len(train)):\n",
    "                history = tuple(train[i - self.order + 1: i])\n",
    "                word = train[i]\n",
    "                if self._counts[(word,) + history] == 0:\n",
    "                    self._wordPairCounts[word] += 1\n",
    "                    self._historyPairCounts[history] += 1\n",
    "                    self._NgramCounts += 1  \n",
    "                self._counts[(word,) + history] += 1.0\n",
    "                self._norm[history] += 1.0\n",
    "                \n",
    "        def counts(self, word_and_history):\n",
    "            return self._counts[word_and_history]\n",
    "\n",
    "        def norm(self, history):\n",
    "            return self._norm[history]\n",
    "        \n",
    "        def wordPairCounts(self,word):\n",
    "            return self._wordPairCounts[word]\n",
    "        \n",
    "        def historyPairCounts(self,history):\n",
    "            return self._historyPairCounts[history]\n",
    "        \n",
    "        def NgramCounts(self):\n",
    "            return self._NgramCounts;\n",
    "\n",
    "    \n",
    "    class KN_smoothingLM(lm.LanguageModel):\n",
    "        \n",
    "        def __init__(self,vocab):\n",
    "            \n",
    "            self.train = lm.inject_OOVs(_snlp_train_song_words)\n",
    "            self.vocab = set(self.train)\n",
    "            self.order = 2\n",
    "            self.D = pow(10,-10)\n",
    "            self.bigramLM = KN_NGramLM(self.train, 2)\n",
    "            self.d = 0.79\n",
    "        \n",
    "        def probability(self,word,*history):\n",
    "            \n",
    "            history_oov = list(history)\n",
    "            for i in range(0,self.order - 1):\n",
    "                if history_oov[i] not in self.vocab:\n",
    "                    history_oov[i] = '[OOV]'\n",
    "                    \n",
    "            history = tuple(history_oov)\n",
    "                            \n",
    "            a = self.bigramLM.norm(history)\n",
    "            b = self.bigramLM.counts((word,) + history)     \n",
    "            c = self.bigramLM.historyPairCounts(history)  \n",
    "            d = self.bigramLM.wordPairCounts(word)\n",
    "            e = self.bigramLM.NgramCounts()\n",
    "            \n",
    "            p = (max((b - self.d),0.0)) / (a+self.D)\n",
    "            KN_lambda = (self.d / (a + self.D)) * c\n",
    "            pContinuation = d / e\n",
    "            probability = p + KN_lambda * pContinuation\n",
    "\n",
    "            return probability\n",
    "\n",
    "    \n",
    "    LM = KN_smoothingLM(vocab)\n",
    "    oovAware_LM = lm.OOVAwareLM(LM,_snlp_test_vocab - LM.vocab)\n",
    "    \n",
    "    return oovAware_LM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 3</font>: Specify Test Data\n",
    "This cell defines the directory to load the test songs from. Currently, this points to the dev set but when we evaluate your notebook we will point this directory elsewhere and use a **hidden test set**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! SETUP 3\n",
    "_snlp_test_dir = _snlp_book_dir + \"/data/ohhla/dev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='green'>Setup 4</font>: Load Test Data and Prepare Language Model\n",
    "In this section we load the test data, prepare the reference vocabulary and then create your language model based on this vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! SETUP 4\n",
    "_snlp_test_song_words = ohhla.words(ohhla.load_all_songs(_snlp_test_dir))\n",
    "_snlp_test_vocab = set(_snlp_test_song_words)\n",
    "_snlp_dev_vocab = set(_snlp_dev_song_words)\n",
    "_snlp_train_vocab = set(_snlp_train_song_words)\n",
    "_snlp_vocab = _snlp_test_vocab | _snlp_train_vocab | _snlp_dev_vocab\n",
    "_snlp_lm = create_lm(_snlp_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 1</font>: Test Normalization (20 pts)\n",
    "Here we test whether the conditional distributions of your language model are properly normalized. If probabilities sum up to $1$ you get full points, you get half of the points if probabilities sum up to be smaller than 1, and 0 points otherwise. Due to floating point issues we will test with respect to a tolerance $\\epsilon$ (`_eps`).\n",
    "\n",
    "Points:\n",
    "* 10 pts: $\\leq 1 + \\epsilon$\n",
    "* 20 pts: $\\approx 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum: 0.9999999999999298, ~1: True, <=1: True\n",
      "Sum: 0.9999999999997035, ~1: True, <=1: True\n",
      "Sum: 0.999999999999591, ~1: True, <=1: True\n"
     ]
    }
   ],
   "source": [
    "#! ASSESSMENT 1\n",
    "_snlp_test_token_indices = [100, 1000, 10000]\n",
    "_eps = 0.000001\n",
    "for i in _snlp_test_token_indices:\n",
    "    result = sum([_snlp_lm.probability(word, *_snlp_test_song_words[i-_snlp_lm.order+1:i]) for word in _snlp_vocab])\n",
    "    print(\"Sum: {sum}, ~1: {approx_1}, <=1: {leq_1}\".format(sum=result, \n",
    "                                                            approx_1=abs(result - 1.0) < _eps, \n",
    "                                                            leq_1=result - _eps <= 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 2: START_POINTS -->\n",
    "20\n",
    "<!-- ASSESSMENT 2: END_POINTS --> \n",
    "points **."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Assessment 2</font>: Apply to Test Data (50 pts)\n",
    "\n",
    "We assess how well your LM performs on some unseen test set. Perplexities are mapped to points as follows.\n",
    "\n",
    "* 0-10 pts: uniform perplexity > perplexity > 550, linear\n",
    "* 10-30 pts: 550 > perplexity > 140, linear\n",
    "* 30-50 pts: 140 > perplexity > 105, linear\n",
    "\n",
    "The **linear** mapping maps any perplexity value between the lower and upper bound linearly to a score. For example, if uniform perplexity is $U$ and your model's perplexity is $P\\leq550$, then your score is $10\\frac{P-U}{550-U}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146.44666357999375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.perplexity(_snlp_lm, _snlp_test_song_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 3: START_POINTS -->\n",
    "0\n",
    "<!-- ASSESSMENT 3: END_POINTS --> points**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Task 2</font>: Describe your Approach\n",
    "\n",
    "< Enter a 500 words max description of your model and the way you trained and tuned it here >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the assignment, I try some methods to implement N-Gram language model using the Kneser-Ney Smoothing. But I finally choose the bigram language using KN-smothing. I give the reason at the end of the description. \n",
    "\n",
    "Here is the formula of the KN_smoothing(bigram):\n",
    "\n",
    "PKN(wi|wi−n+1⋯wi−1)=max(0,CKN(wi−n+1⋯wi)−d)CKN(wi−n+1⋯wi−1)+λ(wi−n+1⋯wi−1)⋅PKN(wi|wi−n+2⋯wi−1) where \n",
    "λ(wi−n+1⋯wi−1)=d / CKN(wi−n+1⋯wi−1)⋅∣{w:CKN(wi−n+1⋯wi−1w)>0}∣\n",
    "\n",
    "According to the material, five data are required to implement a KN_Smoothing:\n",
    "1.\tThe count of word pair (word,history)  appears the training set\n",
    "2.\tThe count of word (history) appears the training set\n",
    "3.\tThe count of word pair (x, word) appears the training set (x is a n-gram history and does not repeat)\n",
    "4.\tThe count of word pair (history, y) appears the training set (y is a word and does not repeat)\n",
    "5.\tThe count of unique word pair (y, x) appears the training set.\n",
    "\n",
    "In order to collect these data efficiently, I simply modify the lm.NgramLM() to KN_Ngram(). Beacuse the 1st and 2nd data can already obtained from the existing functions lm.count((word,)+history) and lm.norm(history). I add three functions: wordPairCounts(), historyPairCounts() and NgramCounts() to get the rest of the required data when initilizing Ngram model.\n",
    "\n",
    "After defining the new Ngram model, I use the inject_OOVs() over the training set and create the new training set of the model. I also use the OOVAwareLM model to deal with the unseen word in the test set. And, before calculating the probibility of a predictive word, I would first replace the word, which is not seen in the trainning set, in the history with the oov symbol so that I can run the bigram kn_smoothing successfully.\n",
    "\n",
    "Another important issue is how to determine constant d in KN-Smoothing. For the choice of parameter d, I run a forloop of d in np.arange(0,1,0.01) to find the best model. I found that in my case, when d = 0.79, it minimizes the perplexity in the development set, which is about 146.6, and ensures normalisation as well. \n",
    "\n",
    "The reason that I choose a bigram model with kn_smoothing instead of higher Ngram model is that I think the trainning set is not large enough and I fail to find efficient way to deal with the unseen history word in the trainning set. When I try the trigram model, I always get the inf perplexity. I think the reason is that, considering the λ in the formula, the parameter ∣{w:CKN(wi−n+1⋯wi−1w)>0}∣ is always 0. It means that very few trigram in the devloping set appear in the trainning set. To tackle this problem, I combine a trigram and a bigram both using  kn_smoothing as a backoff model. But the minimum perplexity is about 190 which is much higher. So I finally choose the bigram model using the kn_smoothing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Assessment 3</font>: Assess Description (30 pts) \n",
    "\n",
    "We will mark the description along the following dimensions: \n",
    "\n",
    "* Clarity (10pts: very clear, 0pts: we can't figure out what you did)\n",
    "* Creativity (10pts: we could not have come up with this, 0pts: Use the unigram model from the lecture notes)\n",
    "* Substance (10pts: implemented complex state-of-the-art LM, 0pts: Use the unigram model from the lecture notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above solution is marked with **\n",
    "<!-- ASSESSMENT 1: START_POINTS -->\n",
    "0\n",
    "<!-- ASSESSMENT 1: END_POINTS --> points**. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
